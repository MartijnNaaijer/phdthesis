{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbless clauses and היה-clauses extrabiblical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the extrabiblical equivalent of the Biblical notebook for the היה-clauses and verbless clauses. The extrabiblical encoding scheme presently differs slightly from that of the BHSA. For more information, look [here](https://github.com/ETCBC/extrabiblical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF is loaded in the old fashioned way, because presently there is no extrabiblical app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, csv, collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.9.0\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "72 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "from tf.fabric import Fabric\n",
    "\n",
    "DATABASE = '~/github'\n",
    "XBIB = 'extrabiblical'\n",
    "\n",
    "TF = Fabric(locations='~/github/extrabiblical/tf/0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s No structure info in otext, the structure part of the T-API cannot be used\n",
      "  0.42s All features loaded/computed - for details use loadLog()\n",
      "   |     0.00s M otext                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B otype                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.08s B oslots               from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s M otext                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B book                 from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B g_suffix             from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B g_cons               from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B g_word_utf8          from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B lex_utf8             from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B g_lex_utf8           from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B verse                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B g_word               from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B book@en              from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B chapter              from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B g_suffix_utf8        from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B __levels__           from otype, oslots, otext\n",
      "   |     0.00s B __order__            from otype, oslots, __levels__\n",
      "   |     0.00s B __rank__             from otype, __order__\n",
      "   |     0.08s B __levUp__            from otype, oslots, __rank__\n",
      "   |     0.07s B __levDown__          from otype, __levUp__, __rank__\n",
      "   |     0.05s B __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s B __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s = otype                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B mother               from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B lex                  from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B typ                  from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B code                 from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B function             from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B rela                 from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.01s B det                  from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B txt                  from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B prs                  from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B kind                 from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B vs                   from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B vt                   from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B sp                   from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s = book                 from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s = chapter              from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s = verse                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B label                from C:/Users/geitb/github/extrabiblical/tf/0.2\n",
      "   |     0.00s B language             from C:/Users/geitb/github/extrabiblical/tf/0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('ensureLoaded', 'TF', 'ignored', 'loadLog')),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Misc',\n",
       "  'messaging',\n",
       "  ('cache',\n",
       "   'error',\n",
       "   'indent',\n",
       "   'info',\n",
       "   'isSilent',\n",
       "   'reset',\n",
       "   'setSilent',\n",
       "   'silentOff',\n",
       "   'silentOn',\n",
       "   'warning')),\n",
       " ('Nodes',\n",
       "  'navigating-nodes',\n",
       "  ('N Nodes', 'sortKey', 'sortKeyTuple', 'otypeRank', 'sortNodes')),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    otype mother lex typ code function rela det txt prs kind vs vt sp book chapter verse label language\n",
    "''')\n",
    "\n",
    "api.loadLog()\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extrabiblical dataset contains the following texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1QH 3\n",
      "1QH 4\n",
      "1QH 5\n",
      "1QH 6\n",
      "1QH 7\n",
      "1QH 8\n",
      "1QH 9\n",
      "1QH 10\n",
      "1QH 11\n",
      "1QH 12\n",
      "1QH 13\n",
      "1QH 14\n",
      "1QH 15\n",
      "1QH 16\n",
      "1QH 17\n",
      "1QH 18\n",
      "1QH 19\n",
      "1QH 20\n",
      "1QH 21\n",
      "1QH 22\n",
      "1QH 23\n",
      "1QH 24\n",
      "1QH 25\n",
      "1QH 26\n",
      "1QH 27\n",
      "1QH 28\n",
      "1QH 29\n",
      "1QM 1\n",
      "1QM 2\n",
      "1QM 3\n",
      "1QM 4\n",
      "1QM 5\n",
      "1QM 6\n",
      "1QM 7\n",
      "1QM 8\n",
      "1QM 9\n",
      "1QM 10\n",
      "1QM 11\n",
      "1QM 12\n",
      "1QS 1\n",
      "1QS 2\n",
      "1QS 3\n",
      "1QS 4\n",
      "1QS 5\n",
      "1QS 6\n",
      "1QS 7\n",
      "Kuntillet_Ajrud 18\n",
      "Kuntillet_Ajrud 19\n",
      "Kuntillet_Ajrud 20\n",
      "Arad 1\n",
      "Arad 2\n",
      "Arad 40\n",
      "Balaam 1\n",
      "Balaam 2\n",
      "Ketef_Hinnom 1\n",
      "Ketef_Hinnom 2\n",
      "Lachish 3\n",
      "Lachish 4\n",
      "Lachish 5\n",
      "Lachish 6\n",
      "Mesha_Stela 1\n",
      "Mesad_Hashavyahu 1\n",
      "Pirqe 1\n",
      "Pirqe 2\n",
      "Pirqe 3\n",
      "Pirqe 4\n",
      "Pirqe 5\n",
      "Pirqe 6\n",
      "Shirata 1\n",
      "Shirata 2\n",
      "Shirata 3\n",
      "Shirata 4\n",
      "Shirata 5\n",
      "Shirata 6\n",
      "Shirata 7\n",
      "Shirata 8\n",
      "Shirata 9\n",
      "Shirata 10\n",
      "Siloam 1\n"
     ]
    }
   ],
   "source": [
    "for book in F.otype.s('book'):\n",
    "    chaps = L.d(book, 'chapter')\n",
    "    for chap in chaps:\n",
    "        print(T.bookName(book), F.chapter.v(chap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of words in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39862\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for wo in F.otype.s('word'):\n",
    "    n += 1\n",
    "    \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few helper functions it is calculated whether a clause is a main clause, a subordinate clause (3 different varieties) or undecided.\n",
    "\n",
    "For more information, check the file main_suboordinate_clauses.ipynb in the folder \"Various\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load main_sub\n",
    "def in_dep_calc(cl):  \n",
    "      \n",
    "    in_dep = ''        \n",
    "    if F.rela.v(cl) == 'ReSu': # is the clause resumptive?\n",
    "        moth_obj = E.mother.f(cl)[0]\n",
    "        in_dep = rela_calc(moth_obj)\n",
    "    else:\n",
    "        in_dep = rela_calc(cl) # does the clause have a dependent CCR?\n",
    "\n",
    "    if in_dep == '':\n",
    "    \twords = L.d(cl, 'word') # is there a wayyiqtol?\n",
    "    \tfor word in words:\n",
    "            if F.vt.v(word) == 'wayq':\n",
    "                in_dep += 'Main'\n",
    "                        \n",
    "    if in_dep == '':  # if everything else does not give a result, we look at the CARC\n",
    "        cl_atoms = L.d(cl, 'clause_atom')\n",
    "        in_dep = carc_calc(cl_atoms)\n",
    "        \n",
    "    return(in_dep)\n",
    "\n",
    "\n",
    "\n",
    "# the feature 'code' plays an important role in determining whether a clause is a main or dependent clause\n",
    "def carc_calc(cl_atoms):\n",
    "    in_dep_c = ''\n",
    "    carc = F.code.v(cl_atoms[0])\n",
    "    if 999 > int(carc) > 499:\n",
    "        in_dep_c += 'SubAdv'\n",
    "    elif int(carc) in {0, 999}:\n",
    "        in_dep_c = 'Main'\n",
    "    elif 17 > int(carc) > 9:\n",
    "        in_dep_c += 'SubAdv'\n",
    "    elif 75 > int(carc) > 50:\n",
    "        in_dep_c += 'SubAdv'\n",
    "    elif 168 > int(carc) > 99:\n",
    "        in_dep_c += 'Main'\n",
    "    elif 500 > int(carc) > 299:\n",
    "        in_dep_c += 'Main'\n",
    "    elif int(carc) in {200, 201}:         \n",
    "        while F.code.v(cl_atoms[0]) in {200, 201}:\n",
    "            cl_atoms = E.mother.f(cl_atoms[0])\n",
    "        carc = F.code.v(cl_atoms[0])\n",
    "        if 999 > int(carc) > 499:\n",
    "            in_dep_c += 'SubAdv'\n",
    "        elif int(carc) in {0, 999}:\n",
    "            in_dep_c = 'Main'\n",
    "        elif 17 > int(carc) > 9:\n",
    "            in_dep_c += 'SubAdv'\n",
    "        elif 75 > int(carc) > 50:\n",
    "            in_dep_c += 'SubAdv'\n",
    "        elif 168 > int(carc) > 99:\n",
    "            in_dep_c += 'Main'\n",
    "        elif 500 > int(carc) > 299:\n",
    "            in_dep_c += 'Main'\n",
    "        elif int(carc) in {220, 221, 222, 223}:\n",
    "            in_dep_c += 'Undc'\n",
    "        \n",
    "    else:\n",
    "        in_dep_c += 'Undc'\n",
    "        \n",
    "    return(in_dep_c)\n",
    "\n",
    "\n",
    "def rela_calc(cl):\n",
    "    in_dep_r = ''\n",
    "    ccr = F.rela.v(cl)\n",
    "    if ccr in {'Subj', 'Objc', 'Cmpl', 'PreC', 'Voct', 'Frnt'}:\n",
    "        in_dep_r += 'SubArg'\n",
    "    elif ccr in {'Attr', 'RgRc', 'Spec'}:\n",
    "        in_dep_r += 'SubMod'\n",
    "    elif ccr in {'Adju', 'PrAd'}:\n",
    "        in_dep_r += 'SubAdv'\n",
    "    elif ccr == 'Coor':\n",
    "        moth_obj = E.mother.f(cl)[0]\n",
    "        if F.otype.v(moth_obj) in {'word', 'phrase'}:\n",
    "            in_dep_r += 'SubMod'\n",
    "        else:\n",
    "            while F.rela.v(moth_obj) == 'Coor':\n",
    "                moth_obj = E.mother.f(moth_obj)[0]\n",
    "            ccr = F.rela.v(cl)\n",
    "            if ccr in {'Subj', 'Objc', 'Cmpl', 'PreC', 'Voct', 'Frnt'}:\n",
    "                in_dep_r += 'SubArg'\n",
    "            elif ccr in {'Attr', 'RgRc', 'Spec'}:\n",
    "                in_dep_r += 'SubMod'\n",
    "            elif ccr in {'Adju', 'PrAd'}:\n",
    "                in_dep_r += 'SubAdv'\n",
    "                \n",
    "        if in_dep_r == '':\n",
    "            if F.otype.v(moth_obj) != 'clause':\n",
    "                in_dep_r += 'SubMod'\n",
    "            else:\n",
    "                cl_atoms = L.d(moth_obj, 'clause_atom')\n",
    "                in_dep_r = carc_calc(cl_atoms)\n",
    "                \n",
    "    return(in_dep_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function mother_clause_calc retrieves the tense of the mother of that clause(atom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mother_tense_calc(cl):\n",
    "    \n",
    "    mother_tense = ''\n",
    "    cl_atoms = L.d(cl, 'clause_atom')\n",
    "    moth = E.mother.f(cl_atoms[0])\n",
    "    if len(moth) == 0:\n",
    "        mother_tense += 'no_mother'\n",
    "    else: \n",
    "        if F.otype.v(moth[0]) in {'word', 'phrase'}:\n",
    "            mother_tense += F.otype.v(moth[0])\n",
    "        else:\n",
    "            cl = L.u(moth[0], 'clause')[0]\n",
    "            if F.kind.v(cl) == 'NC':\n",
    "                mother_tense += 'nominal'\n",
    "            elif F.kind.v(cl) == 'WP':\n",
    "                mother_tense += 'no_pred'\n",
    "                        \n",
    "            else:\n",
    "                phrases = L.d(cl, 'phrase')\n",
    "                pred = False\n",
    "                prec = False\n",
    "                for phr in phrases:\n",
    "                    if F.function.v(phr) in {'Pred', 'PreS', 'PreO'}:\n",
    "                        pred = True\n",
    "                        pred_phr = phr\n",
    "                    elif F.function.v(phr) in {'PreC', 'PtcO'}:\n",
    "                        prec = True\n",
    "                        prec_phr = phr\n",
    "                if pred == True:\n",
    "                    words = L.d(pred_phr, 'word')\n",
    "                    for word in words:\n",
    "                        if F.sp.v(word) == 'verb':\n",
    "                            mother_tense += F.vt.v(word)\n",
    "                elif prec == True:\n",
    "                    words = L.d(prec_phr, 'word')\n",
    "                    for word in words:\n",
    "                        if F.sp.v(word) == 'verb':\n",
    "                            mother_tense += F.vt.v(word)\n",
    "                            \n",
    "    return(mother_tense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list with all the different phrase functions is created (in this case copied from the biblical data). This is used in the main program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_cl_funcs = ['Adju', 'Cmpl', 'Conj', 'EPPr', 'ExsS', 'Exst', 'Frnt', 'IntS', 'Intj', 'Loca', 'ModS', 'Modi', 'NCoS', 'NCop', 'Nega', 'Objc', 'PrAd', 'PrcS', 'PreO', 'PreS', 'PtcO', 'Ques', 'Rela', 'Supp', 'Time', 'Voct', 'Unkn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of each clause it it determined whether it is a relevant clause and its information is stored in the dict cl_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_dict = {}\n",
    "\n",
    "# loop over all the clauses\n",
    "for cl in F.otype.s('clause'):\n",
    "    feat_list = []\n",
    "    cl_kind = F.kind.v(cl)\n",
    "    if cl_kind in {'NC', 'VC'}: \n",
    "        phrases = L.d(cl, 'phrase')\n",
    "        phr_funcs = [F.function.v(phr) for phr in phrases]\n",
    "        \n",
    "        if 'Subj' in phr_funcs and 'PreC' in phr_funcs:\n",
    "            cl_type = ''\n",
    "            if cl_kind == 'VC' and 'Pred' in phr_funcs:\n",
    "                cl_type += 'hyh'\n",
    "            elif cl_kind == 'NC':\n",
    "                cl_type += 'nom'\n",
    "                \n",
    "            if cl_type in {'hyh', 'nom'}:\n",
    "                \n",
    "                # collect basic info about clause\n",
    "                feat_list.append(cl_type) # type of clause: hyh or nom\n",
    "                feat_list.append(str(cl)) # clause id\n",
    "                \n",
    "                bo, ch, ve = T.sectionFromNode(cl)\n",
    "                feat_list.append(bo) # book\n",
    "                feat_list.append(str(ch)) # chapter\n",
    "                feat_list.append(str(ve)) # verse\n",
    "                \n",
    "                feat_list.append(F.typ.v(cl)) # clause type of database\n",
    "                feat_list.append(F.rela.v(cl) + '_') # clause relation\n",
    "                \n",
    "                # eg if book is '1_Samuel', add 'Samuel' to feat_list, relevant for biblical data only\n",
    "                feat_list.append(bo)\n",
    "                \n",
    "                # ebh_lbh\n",
    "                if bo in {'1QM', '1QH', '1QS'}:\n",
    "                    feat_list.append('qumranic')\n",
    "                elif bo in {'Shirata', 'Pirqe'}:\n",
    "                    feat_list.append('rabbinic')\n",
    "                else:\n",
    "                    feat_list.append('epigraphic')\n",
    "                    \n",
    "                # genre\n",
    "                if bo in {'1QH', 'Shirata'}:\n",
    "                    feat_list.append('poetry')\n",
    "                else:\n",
    "                    feat_list.append('prose')\n",
    "                \n",
    "                feat_list.append(F.txt.v(cl)[-1]) # Q, D, N\n",
    "            \n",
    "                if phr_funcs.index('Subj') < phr_funcs.index('PreC'): #subj and prec order\n",
    "                    feat_list.append('SP')\n",
    "                else:\n",
    "                    feat_list.append('PS')\n",
    "                    \n",
    "                # which conjunction\n",
    "                phr_types = [F.typ.v(phr) for phr in phrases]\n",
    "                if 'CP' in phr_types: \n",
    "                    conj = phrases[phr_types.index('CP')]\n",
    "                    words = L.d(conj, 'word')\n",
    "                    words_lex = '_'.join([F.lex.v(wo) for wo in words])\n",
    "                    feat_list.append(words_lex)\n",
    "                else:\n",
    "                    feat_list.append('no_conj')\n",
    "                \n",
    "                # clause length, in verbal clauses the Pred is not counted\n",
    "                if cl_kind == 'VC':\n",
    "                    feat_list.append(str(len(phrases) - 1)) \n",
    "                else:\n",
    "                    feat_list.append(str(len(phrases)))\n",
    "                \n",
    "                subj_pos = phr_funcs.index('Subj')\n",
    "                feat_list.append(F.typ.v(phrases[subj_pos])) #phrase type of subject\n",
    "                feat_list.append(F.det.v(phrases[subj_pos])) #determination of subject\n",
    "                \n",
    "                # length of subj in words\n",
    "                words_subj = L.d(phrases[subj_pos], 'word') # length of subject in words\n",
    "                subj_len = len(words_subj)\n",
    "                \n",
    "                # the following is uncommented in the biblical data file, the suffix is not counted as word automatically there\n",
    "                #for wo in words_subj:                    \n",
    "                #    if not F.prs.v(wo) in {'absent', 'n/a'}:\n",
    "                #        subj_len += 1\n",
    "                feat_list.append(str(subj_len))\n",
    "                \n",
    "                prec_pos = phr_funcs.index('PreC')\n",
    "                feat_list.append(F.typ.v(phrases[prec_pos])) #phrase type of prec\n",
    "                feat_list.append(F.det.v(phrases[prec_pos])) #determination of prec\n",
    "                \n",
    "                # length of prec in words\n",
    "                words_prec = L.d(phrases[prec_pos], 'word')\n",
    "                prec_len = len(words_prec)\n",
    "                \n",
    "                # just as with the subject, uncomment the following for biblical data\n",
    "                #for wo in words_prec:                    \n",
    "                #    if not F.prs.v(wo) in {'absent', 'n/a'}:\n",
    "                #        prec_len += 1\n",
    "                feat_list.append(str(prec_len))\n",
    "            \n",
    "                # main or subordinate clause\n",
    "                feat_list.append(in_dep_calc(cl))\n",
    "                                     \n",
    "                # negation in clause\n",
    "                phr_types = [F.typ.v(phr) for phr in phrases]\n",
    "                if 'NegP' in phr_types:\n",
    "                    feat_list.append('neg')\n",
    "                else:\n",
    "                    feat_list.append('non_neg')\n",
    "                \n",
    "                # aramaic or hebrew\n",
    "                words = L.d(cl, 'word')\n",
    "                feat_list.append(F.language.v(words[0]))\n",
    "                \n",
    "                # collect info about other phrases in clause (present (1) or absent (0))\n",
    "                for item in extra_cl_funcs:   \n",
    "                    if item in phr_funcs:\n",
    "                        feat_list.append('1')\n",
    "                    else:\n",
    "                        feat_list.append('0')\n",
    "                \n",
    "                # tense ot the mother of the clause_atom\n",
    "                feat_list.append(mother_tense_calc(cl))\n",
    "\n",
    "                cl_dict[cl] = feat_list                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are saved in a [csv file](hyh_nom_xbib.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of       cl_type  cl_id     book chapter verse clause_type_etcbc clause_rela  \\\n",
      "39988     hyh  39988      1QH       3     5              InfC       Adju_   \n",
      "40007     nom  40007      1QH       3     9              NmCl         NA_   \n",
      "40008     nom  40008      1QH       3     9              NmCl         NA_   \n",
      "40036     nom  40036      1QH       3    15              NmCl         NA_   \n",
      "40084     nom  40084      1QH       4     7              NmCl         NA_   \n",
      "...       ...    ...      ...     ...   ...               ...         ...   \n",
      "48837     hyh  48837  Shirata      10    21              WxQX         NA_   \n",
      "48838     hyh  48838  Shirata      10    21              XQtl         NA_   \n",
      "48850     hyh  48850   Siloam       1     1              WXQt         NA_   \n",
      "48857     hyh  48857   Siloam       1     1              xQtX         NA_   \n",
      "48862     hyh  48862   Siloam       1     1              WxQX         NA_   \n",
      "\n",
      "         book2     ebh_lbh   genre  ... PreO PreS PtcO Ques Rela Supp Time  \\\n",
      "39988      1QH    qumranic  poetry  ...    0    0    0    0    0    0    1   \n",
      "40007      1QH    qumranic  poetry  ...    0    0    0    0    0    0    0   \n",
      "40008      1QH    qumranic  poetry  ...    0    0    0    0    0    0    1   \n",
      "40036      1QH    qumranic  poetry  ...    0    0    0    0    0    0    0   \n",
      "40084      1QH    qumranic  poetry  ...    0    0    0    0    0    0    0   \n",
      "...        ...         ...     ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "48837  Shirata    rabbinic  poetry  ...    0    0    0    1    0    0    0   \n",
      "48838  Shirata    rabbinic  poetry  ...    0    0    0    0    0    0    0   \n",
      "48850   Siloam  epigraphic   prose  ...    0    0    0    0    0    0    0   \n",
      "48857   Siloam  epigraphic   prose  ...    0    0    0    0    0    0    0   \n",
      "48862   Siloam  epigraphic   prose  ...    0    0    0    0    0    0    0   \n",
      "\n",
      "      Voct Unkn   mother  \n",
      "39988    0    0     ptca  \n",
      "40007    0    0     perf  \n",
      "40008    0    0  nominal  \n",
      "40036    0    0  nominal  \n",
      "40084    0    0  nominal  \n",
      "...    ...  ...      ...  \n",
      "48837    0    0  nominal  \n",
      "48838    0    0     perf  \n",
      "48850    0    0  nominal  \n",
      "48857    0    0     wayq  \n",
      "48862    0    0     perf  \n",
      "\n",
      "[857 rows x 51 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_hjh_nom = pd.DataFrame(cl_dict).T\n",
    "\n",
    "header = ['cl_type', 'cl_id', 'book', 'chapter', 'verse', 'clause_type_etcbc', 'clause_rela', 'book2', 'ebh_lbh', 'genre', 'txt_type', 's_p_order', 'CP', 'cl_len', 'subj_type', 'subj_det', 'subj_len', 'pc_type', 'pc_det', 'pc_len', 'main_sub', 'nega', 'language']\n",
    "\n",
    "for item in extra_cl_funcs:\n",
    "    header.append(item)\n",
    "header.append('mother')\n",
    "\n",
    "df_hjh_nom.columns = header \n",
    "\n",
    "df_hjh_nom.to_csv(\"hyh_nom_xbib.csv\", index = False)\n",
    "\n",
    "print(df_hjh_nom.head)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
